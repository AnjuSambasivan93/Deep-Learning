{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Denoising_autoencoder_with_a_twist(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3okPAm4HrPpY"
      },
      "source": [
        "Working with MNIST dataset again\n",
        "Importing nessesary libraries first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30jGk2GvnZCO"
      },
      "source": [
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHQZPennrtTD"
      },
      "source": [
        "Importing MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK9geVGkN5W1"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLpYXZnarxIc"
      },
      "source": [
        "Checking data dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPwly-D1OQV8"
      },
      "source": [
        "print(\"Training data shape: \", x_train.shape) # (60000, 28, 28) -- 60000 images, each 28x28 pixels\n",
        "print(\"Test data shape\", x_test.shape) # (10000, 28, 28) -- 10000 images, each 28x28\n",
        "print(\"Training response shape:, \", y_train.shape)\n",
        "print(\"Testing response shape: \", y_test.shape)\n",
        "\n",
        "image_size = (x_train.shape[1], x_train.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvPsLNtXrwX_"
      },
      "source": [
        "Need to flatten the images to work with MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6mAeu4Ihwql"
      },
      "source": [
        "# Flatten the images\n",
        "image_vector_size = image_size[0] * image_size[1] # 28 * 28\n",
        "x_train = x_train.reshape(x_train.shape[0], image_vector_size) /255.\n",
        "x_test = x_test.reshape(x_test.shape[0], image_vector_size) /255.\n",
        "print(x_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwkVeuaSrYAa"
      },
      "source": [
        "We are going to corrupt MNIST images with noise and train a denoising autoencoder to reconstruct the original images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP62B3tPo7fL"
      },
      "source": [
        "noise_factor = 0.7 #determines how much images are corrupted\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeZaWlW-sFH5"
      },
      "source": [
        "Let's plot one such image with noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UofxONVho_Ow"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i=5\n",
        "#n = 10\n",
        "#plt.figure(figsize=(20, 2))\n",
        "#for i in range(n):\n",
        "#    ax = plt.subplot(1, n, i)\n",
        "plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "plt.gray()\n",
        "#    ax.get_xaxis().set_visible(False)\n",
        "#    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgEI5B-ksLX7"
      },
      "source": [
        "Below we define an autoencoder model with the dimension of bottleneck layer of 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRP5PYQtqaBt"
      },
      "source": [
        "# this is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# this is our input placeholder\n",
        "input_img = Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# this model maps an input to its reconstruction\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5DhJhEjsZJz"
      },
      "source": [
        "We can also separetely access encoder and decoder parts of this model[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs1mYmTDrIQU"
      },
      "source": [
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FA8R06SrNCx"
      },
      "source": [
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "# retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# create the decoder model\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9n9bRBMserk"
      },
      "source": [
        "Let's compile our autoencoder with Adadelta optimiser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le9uLlAbqnJH"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig0WHLx_s0vU"
      },
      "source": [
        "Let's fit the model for 50 epoch, notice that we don't use Labels at all anymore!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAKWIQSYrc-u"
      },
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAnK4dxTtHA_"
      },
      "source": [
        "Let's check out visually how well our autoencoder is doing. We will visualise the results of our autoencoder applied to test set of noisy images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO2dt00nq1NG"
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test_noisy)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reLUGB1xtGHW"
      },
      "source": [
        "We will visualise the original images in the top row\n",
        "and the reconstructed images in the bottow row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cua3w4APsrTE"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wniooVoCuT70"
      },
      "source": [
        "Yay!!! It did the job quite well!! Try to vary noise parameter above.\n",
        "But now let's apply this autoencoder to noisy version of the Fashion-MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_JHfUsQx88s"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(Fx_train, Fy_train), (Fx_test, Fy_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcu8bPdFyKTC"
      },
      "source": [
        "print(\"Training data shape: \", x_train.shape) # (60000, 28, 28) -- 60000 images, each 28x28 pixels\n",
        "print(\"Test data shape\", x_test.shape) # (10000, 28, 28) -- 10000 images, each 28x28\n",
        "print(\"Training response shape:, \", y_train.shape)\n",
        "print(\"Testing response shape: \", y_test.shape)\n",
        "\n",
        "Fimage_size = (Fx_train.shape[1], Fx_train.shape[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWKhVJHXyORu"
      },
      "source": [
        "# Flatten the images\n",
        "Fimage_vector_size = Fimage_size[0] * Fimage_size[1] # 28 * 28\n",
        "Fx_train = Fx_train.reshape(Fx_train.shape[0], Fimage_vector_size) /255.\n",
        "Fx_test = Fx_test.reshape(Fx_test.shape[0], Fimage_vector_size) /255.\n",
        "print(Fx_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbPmMdO4upZX"
      },
      "source": [
        "We applied noise to the Fashion-MNIST images below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gokrTgjuyfKZ"
      },
      "source": [
        "noise_factor = 0.7\n",
        "Fx_train_noisy = Fx_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=Fx_train.shape) \n",
        "Fx_test_noisy = Fx_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=Fx_test.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaOAJxvduwlf"
      },
      "source": [
        "Let's now apply previously trained autoencoder to reconstruct them back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoxrbAh6yp-I"
      },
      "source": [
        "# encode and decode some digits\n",
        "# note that we take them from the *test* set\n",
        "Fencoded_imgs = encoder.predict(Fx_test_noisy)\n",
        "Fdecoded_imgs = decoder.predict(Fencoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2S20MvU2_xT"
      },
      "source": [
        "Fdecoded_imgs =autoencoder.predict(Fx_test_noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tndGJRiu49S"
      },
      "source": [
        "Woah! So close. Let's visuale the results!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVBWEBsEyx8j"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20  # how many digits we will display\n",
        "plt.figure(figsize=(40, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(Fx_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(Fdecoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56OQAwX0u9eg"
      },
      "source": [
        "Are you suprised? =) Can you explain what happened. \n",
        "Let's apply autoencoder to these weird looking symbols again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MBw80M3L9sq"
      },
      "source": [
        "FMdecoded_imgs=autoencoder.predict(Fdecoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mP9cNTWMH37"
      },
      "source": [
        "# use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20  # how many digits we will display\n",
        "plt.figure(figsize=(40, 4))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(Fdecoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(FMdecoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kaze1vGvQIQ"
      },
      "source": [
        "Try do another way around - train an autoencoder on Fashion-MNIST and apply it to MNIST"
      ]
    }
  ]
}